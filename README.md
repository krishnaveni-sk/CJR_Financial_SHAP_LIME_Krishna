ğŸ“Œ CJR Financial SHAP & LIME Project â€” Krishna

This project demonstrates interpretable machine learning using SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) for financial time-series prediction.
The project was completed as part of the Cultus Job Readiness (CJR) Program.

ğŸ“ Project Structure
â”œâ”€â”€ CJR_Financial_SHAP_LIME_Krishna.ipynb   # Main notebook (full workflow)
â”œâ”€â”€ processed_financial_dataset.csv         # Preprocessed dataset
â”œâ”€â”€ X_test_data.csv                         # Test features
â”œâ”€â”€ Y_test_data.csv                         # Test labels
â”œâ”€â”€ shap_summary.png                        # SHAP global feature importance
â”œâ”€â”€ shap_local_0.png to shap_local_9.png    # SHAP local explanations (10 instances)
â”œâ”€â”€ lime_local_0.html to lime_local_9.html  # LIME local explanations (10 instances)
â””â”€â”€ README.md                               # Project documentation

ğŸ§  Project Goal

To predict 5-day future stock movement and understand why the model makes each prediction using interpretability methods.

Two models were trained:

XGBoost Classifier

Neural Network Classifier

Both models were analyzed using:

âœ” Global interpretability â€” Feature importance

âœ” Local interpretability â€” Instance-wise explanations

âœ” Comparative analysis â€” SHAP vs LIME

ğŸ”§ Technologies Used

Python

Google Colab

Pandas, NumPy

scikit-learn

XGBoost

TensorFlow / Keras

SHAP

LIME

Matplotlib / Seaborn

ğŸ› ï¸ Steps Performed
1ï¸âƒ£ Data Preparation

Loaded the financial dataset from CSV

Checked for stationarity

Created lag features

Created short-term return & volatility features

Split into train/test sets

2ï¸âƒ£ Model Training

Two non-linear models were trained:

XGBoost Classifier

Neural Network Classifier (TensorFlow)

Hyperparameters were tuned using:

Learning rate adjustments

Depth changes

Optimizer tuning

Batch size variation

3ï¸âƒ£ SHAP Analysis

Generated:

Global Summary Plot

Top feature contributions

Local explanations (10 instances) using waterfall plots

Files saved:

shap_summary.png
shap_local_0.png ... shap_local_9.png

4ï¸âƒ£ LIME Analysis

For the same 10 instances:

Generated HTML explanation files

Highlighted positive & negative contributions

Compared LIME vs SHAP reasoning

Files saved:

lime_local_0.html ... lime_local_9.html

5ï¸âƒ£ Comparative Interpretation

A complete text-based comparison was generated:

Stable patterns from SHAP

Instance-specific variations from LIME

Why certain features strongly influence volatility

Practical insights useful for financial analysts

ğŸ“Š Key Insights

Lag-based features and volatility indicators were the strongest predictors.

SHAP showed consistent dominance of Lag1, Return_5d, Volatility_5d.

LIME provided deep clarity for each individual prediction.

Both models agreed on major drivers, increasing confidence in predictions.

ğŸ“¦ Deliverables Included

âœ” Preprocessed dataset
âœ” Model training code
âœ” Hyperparameter tuning
âœ” SHAP global & local explanations
âœ” LIME explanations (10 instances)
âœ” Comparative analysis
âœ” Complete README documentation

ğŸ“Œ Author

Krishnaveni S
Cultus Job Readiness Program
Interpretable ML Project â€” SHAP & LIME
